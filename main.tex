
%\RequirePackage{pdf15}

\documentclass{beamer}

\usepackage[utf8]{inputenc}

\usepackage{mystyle}

\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{subcaption}

\usepackage{natbib}
\bibliographystyle{apalike}
%\usepackage[style=authortitle,backend=biber]{biblatex}
%\addbibresource{anthology.bib}
%\addbibresource{emnlp2020.bib}
\renewcommand{\footnotesize}{\scriptsize}

\usepackage{tikz-dependency}
\usetikzlibrary{shapes.arrows, positioning, fit, bayesnet,
    arrows,backgrounds,patterns,matrix,calc,shadows,plotmarks,
    shapes,positioning,automata,positioning,spy,scopes,chains,decorations,decorations.pathreplacing}

\newcommand{\FancyUpArrow}{\begin{tikzpicture}[baseline=-0.3em]
\node[single arrow,draw,rotate=90,single arrow head extend=0.2em,inner
ysep=0.2em,transform shape,line width=0.05em,top color=green,bottom color=green!50!black] (X){};
\end{tikzpicture}}
\newcommand{\FancyDownArrow}{\begin{tikzpicture}[baseline=-0.3em]
\node[single arrow,draw,rotate=-90,single arrow head extend=0.2em,inner
ysep=0.2em,transform shape,line width=0.05em,top color=red,bottom color=red!50!black] (X){};
\end{tikzpicture}}

\AtBeginSection[]{
  \begin{frame}
  \vfill
  \centering
  \begin{beamercolorbox}[sep=8pt,center,shadow=true,rounded=true]{title}
    \usebeamerfont{title}\insertsectionhead\par%
  \end{beamercolorbox}
  \vfill
  \end{frame}
}

% quotes
\usepackage[style=british]{csquotes}

\def\signed #1{{\leavevmode\unskip\nobreak\hfil\penalty50\hskip1em
  \hbox{}\nobreak\hfill #1%
  \parfillskip=0pt \finalhyphendemerits=0 \endgraf}}

\newsavebox\mybox
\newenvironment{aquote}[1]
  {\savebox\mybox{#1}\begin{quote}\openautoquote\hspace*{-.7ex}}
  {\unskip\closeautoquote\vspace*{1mm}\signed{\usebox\mybox}\end{quote}}

%Information to be included in the title page:
\title{Word Games}
\author{J Chiu}

\setbeamertemplate{navigation symbols}{} 
\setbeamertemplate{footline}[frame number]

\begin{document}

\begin{frame}[plain]
\titlepage
\end{frame}

\begin{frame}
\frametitle{3 Challenges}
\begin{itemize}
\item Modular models
    \begin{itemize}
    \item Dialogue model = local meaning representation -
        belief state - dialog act - utterance generation
    \item Various works supervise particular parts
        then leave others to be implicitly learned through
        neural nets
    \item Results in very task-specific architectures
    \item Can we break down tasks to allow for
        more component sharing across different tasks, as well as
        semi-supervised learning?
    \end{itemize}
\item Less complicated meaning representations
    \begin{itemize}
    \item Meaning representations vary in granularity
    \item Can we learn a minimal task-specific subset of a meaning
        representation formalism?
    \end{itemize}
\item Adapting to partners
    \begin{itemize}
    \item Partner model allows forward modeling, learned over
        a multiple round game or repeated games
    \item Adapt opaque neural model or hierarchical bayesian model?
    \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Natural Language Interaction}
\begin{itemize}
\item Interaction (through language) is important 
    \begin{itemize}
    \item Cannot fully automate every task,
        i.e. task-oriented or information seeking dialogues
        require human input
    \item Must handle diverse non-expert human input,
        although input may map to a low-dimensional manifold
    \item High levels of ambiguity must be resolved via interaction
    \end{itemize}
\item Interaction (through language) is hard 
    \begin{itemize}
    \item Human input is expensive, so supervision is limited
    \item In order to make certain problem aspects tractable,
        must make sacrifices in other areas
        (toy domain = out of distribution for pretrained models)
    \end{itemize}
\item What are the main challenges in interaction,
    and what are the tradeoffs of different approaches?
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Types of Dialogue Games}
\begin{itemize}

\item Task-oriented: Wizard of Oz (WoZ)
    \begin{itemize}
    \item \citet{tseng2019semisupdialogue}: Wizard obtains
        task from human then executes it.
    \end{itemize}
\item Deliberation / reference / signal
    \begin{itemize}
    \item \citet{udagawa2019oc}: Visual reference game
        with latent translated views.
        Each player gets a different petri dish view
        of the same underlying game board, and players must
        select the same object on the board.
    \end{itemize}
\item Information seeking / inquiry
    \begin{itemize}
    \item \citet{yu2019questions}: WoZ-style answer providing
        where asker does not know exact question.
        Latent true question (to all), WoZ must answer
    \end{itemize}
\item Persuasion / negotiation
    \begin{itemize}
    \item \citet{lewis2017dnd}: Negotiation over an observed
        set of item with latent utilities for each agent.
    \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Types of Dialogue Games}
In all cases, the game can be (indirectly) solved by resolving a latent variable

\begin{itemize}
\item When is this tractable, and why do no new methods do this?
\item New (ie basically all) methods rely on supervision
\item If they do not, it is because the game has a trivial solution
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Talk with Nori}
\begin{itemize}
\item Planning doesnt really exist in most dialogue games,
    the games are too simple
\item Referring expressions in OneCommon can be outliers in terms of complexity.
    Complexity in real world image+text data comes from large noun classes
    and relatively simple phrases.
    Still seems like an interesting testbed though,
    and maybe there is an argument for OneCommon,
    despite its artificial difficulty (maybe people like talking about stars?).
\item Latent variable models for adaptation still seem interesting,
    should read Hawkins' work.
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Types of Dialogue Games: Latent goals and strategy}
What are the latent variables in each type?
\begin{itemize}
\item Task-oriented
    \begin{itemize}
    \item Latent task slots
    \end{itemize}
\item Deliberation / reference / signal
    \begin{itemize}
    \item Varies per game
    \end{itemize}
\item Information seeking / inquiry
    \begin{itemize}
    \item Infer true question, find answer
    \end{itemize}
\item Persuasion / negotiation
    \begin{itemize}
    \item Infer utilities, exploit
    \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Types of Dialogue Games: Latent goals and strategy}
\begin{itemize}
\item Tasks must be interesting enough so that
    latent quantities cannot be inferred with a single utterance,
    reducing them to single turn games
    \begin{itemize}
    \item High degree of ambiguity / distractors
        or large number of slots to fill (combinatorial)
    \end{itemize}
\item Break down latent quantities and use heuristics
    to make assumptions on structure
    \begin{itemize}
    \item For example, choosing an ordering of WoZ slots:
        When choosing a restaurant, first figure out
        time, then cuisine, and finally price
    \item Will likely remain task-specific
    \end{itemize}
\item What other parts can we learn?
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Belief State Tracking}
\begin{itemize}
\item The incremental inference procedure is known as belief state tracking (BST)
\item Local semantics are aggregated into belief state, which informs
    high-level strategic decisions
\item Seems difficult to learn language, high level strategy,
    belief state updating, and low level parsing at the same time
\item Ablate how structure influences each of these
\end{itemize}
\end{frame}


\begin{frame}
\frametitle{Language Games}

\begin{itemize}
\item Games offer a testbed for the development of methods
    \begin{itemize}
    \item Allow designers to control difficulty and simplicity
    \end{itemize}
\item Allowing interaction through language increases the population of players
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Meaning reps}
\begin{itemize}
\item In full generality, this problem is often encountered in hierarchical RL
    \begin{itemize}
    \item Less bleak in the language gamesetting
    \item Games are often very simple and can be constrained to small horizons,
        for example He He engineered a parser and policy that basically solves
        the negotiation task
    \end{itemize}
\item Many text-specific meaning representations (MR) to choose from
    \begin{itemize}
    \item Many are too complex
    \item Can we leverage existing MRs to learn a minimal task-specific
        representation that balances utility and expressivity?
    \end{itemize}
\end{itemize}
\end{frame}


\begin{frame}
\frametitle{Contributions}
\begin{itemize}
\item Under a unified Bayesian game perspective of dialog games,
    present formulations for different classes of dialogs:
    signaling, negotation?
\item Provide pipelined variational Bayesian framework for learning
    to play dialog games from offline data,
    with and without granular annotations
\item Good results
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Tasks}
\begin{itemize}
\item Task-oriented dialogue: Multi-WoZ
\item Negotation: Deal-or-no-deal
\item Reference: OneCommon
\item Information-Seeking: Birds
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Generation under uncertainty}
\begin{itemize}
\item \cite{lemon2010uncertain-generation}
\end{itemize}
\end{frame}

\begin{frame}[allowframebreaks]
\frametitle{Citations}
%\printbibliography
\bibliography{anthology.bib}
\end{frame}

\end{document}
